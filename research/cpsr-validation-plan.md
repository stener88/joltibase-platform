# Customer Problem Stack Ranking: Joltibase Validation Plan

## Executive Summary

This document outlines a Customer Problem Stack Ranking (CPSR) research plan to validate whether Joltibase's core value proposition solves a high-priority problem for target customers. CPSR reveals where your solution ranks among ALL problems customers face in a given activity - not just whether they like your idea.

**Key Question:** Does "AI-powered + visually-editable email campaign creation" solve a burning pain point üî• or just a mild inconvenience üôÑ?

**Timeline:** 2-3 weeks to complete research and analyze results  
**Budget:** $0-50 (survey tool subscription if needed)  
**Expected Outcome:** Clear validation or pivot signal based on real customer priorities

---

## Why Customer Problem Stack Ranking?

Traditional customer discovery interviews can mislead you because:
- People are too polite to say your idea isn't important
- They'll say "that sounds interesting" to avoid hurting your feelings
- You hear what you want to hear (confirmation bias)

CPSR forces customers to **rank your problem against every other problem they face**, revealing true priorities through relative comparison.

### Real-World Evidence
The CPSR methodology helped the author of the original article learn more in 2 hours than 100+ customer discovery interviews. Their carefully researched value proposition ranked **dead last** - but the research also revealed they were solving the RIGHT problem with the WRONG vocabulary.

---

## Part 1: Research Design

### The Core Question

**"What is the most frustrating part of creating email campaigns for your business?"**

**Why this question:**
- Broad enough to explore all email marketing problems
- Focused on the specific activity where Joltibase operates
- Prompts emotional response ("frustrating") for honest feedback
- Doesn't mention AI, templates, or any solution concepts

### Activity of Focus

**Email Campaign Creation** - The end-to-end process of:
1. Deciding what to send
2. Creating the email design and copy
3. Setting up the campaign
4. Sending and tracking results

This covers the entire workflow where Joltibase competes, not just the design portion.

---

## Part 2: Problem Statements

### Overview

We'll test 12-15 problem statements:
- 3-4 statements about Joltibase's core value propositions (phrased as problems)
- 8-11 peripheral problem statements covering other email marketing pain points
- Participants can add their own statements during the survey

### Critical Rules for Problem Statements

‚úÖ **DO:**
- Phrase as problems, NOT solutions
- Use customer vocabulary, not marketing jargon
- Be specific enough to be actionable
- Test multiple variations of your core value prop

‚ùå **DON'T:**
- Mention your product or solution
- Use technical terms customers don't use
- Combine multiple problems into one statement
- Lead participants toward your preferred answer

---

## Part 3: Joltibase-Specific Problem Statements

### Core Value Proposition Problems

These translate Joltibase's "AI + visual editing" value prop into customer problems:

**Problem 1A: Design Time** (Primary)
> "Creating beautiful, professional-looking email designs takes too long when I'm trying to launch campaigns quickly."

**Problem 1B: Design Quality** (Alternative vocabulary)
> "My email designs look amateur compared to big brands, even though I spend hours trying to make them look good."

**Problem 1C: Template Starting Point** (Alternative framing)
> "Starting from a blank canvas is overwhelming - I waste time staring at templates wondering which one will convert best."

**Problem 1D: Design Skills** (Alternative framing)
> "I don't have design skills, so my emails never look as polished as I want them to, no matter which tool I use."

### Why Multiple Variations?

The article author discovered they were solving the RIGHT problem but using the WRONG vocabulary. Testing multiple phrasings helps you find the words that resonate with customers.

---

## Part 4: Peripheral Problem Statements

These cover other email marketing problems your target customers face. Include a mix of strategic, tactical, and technical problems.

### Strategic Problems

**Problem 2: Content Strategy**
> "I never know what content to send to my email list - I struggle with ideas for every campaign."

**Problem 3: Sending Frequency**
> "I'm afraid to email my list too often and lose subscribers, so I procrastinate and send campaigns infrequently."

**Problem 4: Audience Segmentation**
> "My email list is one big group, but I know different subscribers want different content and I don't know how to segment effectively."

### Tactical/Workflow Problems

**Problem 5: Copy Writing**
> "Writing compelling email copy that gets people to click is harder than I expected - my open rates are decent but click rates are low."

**Problem 6: A/B Testing**
> "I want to A/B test my emails to improve performance, but setting up tests is confusing and I don't know what to test."

**Problem 7: Technical Setup**
> "The technical setup for email campaigns (merge tags, UTM tracking, etc.) is tedious and I make mistakes that embarrass me."

### Platform/Tool Problems

**Problem 8: Platform Switching**
> "I've switched email platforms 2-3 times trying to find the right fit, and migrating contacts/campaigns is a nightmare every time."

**Problem 9: Platform Pricing**
> "Email platform pricing grows too fast as my list grows - I hit expensive tiers before I'm making enough revenue from email."

**Problem 10: Deliverability**
> "I don't understand why some of my emails land in spam folders, and troubleshooting deliverability issues is overwhelming."

### Growth/Analytics Problems

**Problem 11: List Growth**
> "Growing my email list is slow - I don't have enough high-converting lead magnets or opt-in strategies."

**Problem 12: Analytics Interpretation**
> "I get data from my email platform (opens, clicks, etc.) but I don't know how to interpret it or what actions to take."

---

## Part 5: Target Customer Segments

### Why Segmentation Matters

If you survey "email marketers" broadly, you'll get noisy data because:
- Enterprise marketers have different problems than solopreneurs
- E-commerce vs SaaS vs coaching businesses have different priorities
- Technical vs non-technical users face different barriers

**Rule:** Pick ONE specific segment for your first CPSR round.

### Recommended Primary Segment

**Solopreneur Creators (1K-10K email subscribers)**

**Profile:**
- Running their own business (coaching, courses, digital products, consulting)
- Email list size: 1,000 - 10,000 subscribers
- Currently using: Mailchimp, ConvertKit, MailerLite, or Flodesk
- Spending: $30-100/month on email marketing
- Email frequency: 1-4 times per month
- Technical skill: Low to medium (not developers)

**Why this segment:**
- Most likely to value speed + design quality (time-poor, brand-conscious)
- Budget-conscious (will switch tools for better value)
- Active in online communities (easier to reach)
- Growing market (creator economy boom)
- Joltibase's pricing will fit their budget

**Where to find them:**
- IndieHackers
- Twitter (#buildinpublic, #solopreneur)
- Reddit: r/Entrepreneur, r/smallbusiness
- Indie newsletter communities
- Product Hunt maker community

### Alternative Segments (Test Later)

**Segment 2: Small Business Marketing Managers**
- Profile: Marketing lead at 5-20 person company, managing email + other channels
- Different problems: Likely to prioritize segmentation, automation, integration over speed

**Segment 3: Agency Email Specialists**
- Profile: Creating campaigns for multiple clients
- Different problems: Likely to prioritize white-label, client collaboration, templates

---

## Part 6: Survey Setup

### Recommended Tools

**Option 1: TypeForm** (Recommended)
- Beautiful UI
- Native ranking/sorting question type
- Free tier: 10 questions, 100 responses
- Paid: $25/month for unlimited

**Option 2: Google Forms**
- Free
- No native ranking (use grid or multiple choice workaround)
- Less beautiful but functional

**Option 3: Notion + Manual Sorting**
- Create Notion database
- Participants drag-and-drop to rank
- Free but requires more manual setup

### Survey Structure

**Page 1: Qualification**
- Are you currently sending email campaigns for a business? (Yes/No)
- What's your role? (Business owner, Marketing manager, etc.)
- How many subscribers do you have? (0-1K, 1K-10K, 10K+, etc.)
- Filter out anyone not in your target segment

**Page 2: The Question**
> "What is the most frustrating part of creating email campaigns for your business?"
>
> Below are common problems email marketers face. Please **rank them from most frustrating (#1) to least frustrating**. You can also add problems we missed.

**Page 3: Stack Ranking Interface**
- Display all 12 problem statements
- Drag-and-drop to rank (TypeForm) or number input (Google Forms)
- "Add your own problem" text field at bottom

**Page 4: Follow-up (Optional)**
- "Which problem have you tried to solve in the last 6 months?"
- "Would you be interested in a beta test of a solution?" (Email capture)

### Survey Length

- Target completion time: 3-5 minutes
- Keep problem list to 12-15 statements max
- Any longer and completion rates drop significantly

---

## Part 7: Distribution Strategy

### Target Response Count

**Minimum:** 30 responses (statistical significance starts here)  
**Good:** 50-75 responses (clear patterns emerge)  
**Excellent:** 100+ responses (high confidence)

### Distribution Channels

**Channel 1: Direct Outreach (Highest quality)**
- Find 100-200 people in target segment
- Send personalized DMs on Twitter, LinkedIn, or community Slack
- Expected response rate: 20-30%
- Time investment: 3-5 hours

**Channel 2: Community Posts (Medium quality)**
- Post in relevant subreddits, Slack communities, forums
- Less targeted but faster reach
- Expected response rate: 5-10%
- Time investment: 1-2 hours

**Channel 3: Your Network (Fastest)**
- Email your network, share on social media
- Fastest but may introduce bias
- Expected response rate: 10-15%
- Time investment: 30 minutes

### Recommended Timeline

**Week 1:**
- Days 1-2: Set up survey
- Days 3-5: Direct outreach (50 DMs)
- Days 6-7: Community posts

**Week 2:**
- Days 1-3: More outreach (50 more DMs)
- Days 4-5: Follow-ups
- Days 6-7: Close survey and analyze results

### Quality vs Quantity

**Better:** 30 highly-qualified responses from your exact target segment  
**Worse:** 100 responses from random "email users"

Filter aggressively during qualification. If someone doesn't match your target segment, don't include their ranking in your analysis.

---

## Part 8: Results Analysis

### Step 1: Calculate Average Rankings

For each problem statement, calculate:
- **Average rank:** Sum of all ranks √∑ number of responses
- **#1 votes:** How many people ranked it as their #1 problem
- **Top 3 votes:** How many people ranked it in their top 3

**Example:**
```
Problem 1A: "Design takes too long"
- Average rank: 3.2
- #1 votes: 8 (out of 50)
- Top 3 votes: 22 (44%)
```

### Step 2: Sort by Priority

Create a table sorted by average rank (lowest = highest priority):

| Rank | Problem | Avg | #1 Votes | Top 3 |
|------|---------|-----|----------|-------|
| 1 | Problem X | 2.1 | 18 | 65% |
| 2 | Problem Y | 3.4 | 9 | 52% |
| 3 | **Joltibase 1A** | **3.8** | **8** | **44%** |

### Step 3: Interpret Results

**Scenario A: Joltibase problem ranks #1-2**
‚úÖ **Signal:** STRONG VALIDATION
- **Action:** Full steam ahead with current positioning
- **Next steps:** Build MVP, get beta users, iterate on solution

**Scenario B: Joltibase problem ranks #3-5**
‚ö†Ô∏è **Signal:** MODERATE VALIDATION
- **Action:** Pivot messaging/positioning, but core idea might be solid
- **Next steps:** Interview top 10 respondents to understand #1-2 problems better
- **Question:** Can you solve the #1 problem AND your original problem?

**Scenario C: Joltibase problem ranks #6+**
üö® **Signal:** WEAK VALIDATION
- **Action:** Serious pivot needed - you're solving the wrong problem
- **Next steps:** Deep dive into #1-2 ranked problems
- **Question:** Are these problems you can/want to solve?

**Scenario D: Different wording of Joltibase problem ranks high**
üí° **Signal:** RIGHT PROBLEM, WRONG VOCABULARY
- **Action:** Keep solution, completely rewrite messaging/positioning
- **Next steps:** Use customer vocabulary everywhere (landing page, onboarding, etc.)
- **Example:** You said "AI-powered design" but customers say "making emails look professional"

### Step 4: Look for Patterns

**Analyze by segment:**
- Do solopreneurs with 1-5K subs rank differently than 5-10K subs?
- Do ConvertKit users have different priorities than Mailchimp users?

**Analyze added problems:**
- What problems did participants add that you didn't anticipate?
- Are added problems related to your solution or completely different?

**Analyze qualitative feedback:**
- Read any comments participants added
- Look for emotional language ("hate", "frustrating", "overwhelming")
- Note specific phrases customers use

### Step 5: Decision Framework

Use this decision tree:

```
Did a Joltibase problem rank in top 3?
‚îú‚îÄ YES ‚Üí Did it use your original vocabulary?
‚îÇ  ‚îú‚îÄ YES ‚Üí ‚úÖ Validated! Build it.
‚îÇ  ‚îî‚îÄ NO ‚Üí ‚ö†Ô∏è Rewrite all messaging with customer vocab
‚îÇ
‚îî‚îÄ NO ‚Üí Can you solve the #1 ranked problem?
   ‚îú‚îÄ YES ‚Üí üîÑ Pivot to solve that problem instead
   ‚îî‚îÄ NO ‚Üí üö® Major pivot needed (different problem or different segment)
```

---

## Part 9: Post-Research Actions

### If Validated (Top 3 Ranking)

**Immediate actions:**
1. Rewrite landing page using exact problem vocabulary from survey
2. Update onboarding flow to emphasize the validated problem
3. Reach out to top respondents for beta testing
4. Create case studies around solving the validated problem
5. Build MVP features that directly address the top-ranked problem

**Example:**
If "Design takes too long" ranked #1, your landing page headline should be:
- ‚úÖ "Create professional email designs in minutes, not hours"
- ‚ùå "AI-powered email design platform"

### If Invalidated (Rank 6+)

**Immediate actions:**
1. Schedule follow-up interviews with 10-15 respondents
2. Deep dive into problems ranked #1-3
3. Assess: Can you solve those problems better than existing solutions?
4. Assess: Do you WANT to solve those problems?
5. Consider: Should you pivot segment instead of problem?

**Example:**
If "List growth" ranked #1 but you don't want to build lead magnet tools, consider:
- Different segment (agency specialists instead of solopreneurs)
- Different positioning (Joltibase as the post-list-growth tool)
- Major pivot (build the list growth tool instead)

### If Vocabulary Mismatch

**Immediate actions:**
1. Export all customer phrases for the validated problem
2. Rewrite EVERYTHING using customer vocabulary:
   - Landing page
   - Onboarding
   - In-app copy
   - Marketing emails
   - Social media
3. Run second CPSR with new vocabulary to confirm
4. Update brand messaging guidelines

**Example from original article:**
- They were using: "Validation research tools"
- Customers were saying: "Testing ideas before building"
- Same problem, completely different words = dead last ranking

---

## Part 10: Survey Iteration Strategy

### Round 1: Broad Validation (This plan)
- **Goal:** Find if Joltibase solves a top 3 problem
- **Scope:** 12-15 problems across email marketing
- **Segment:** Solopreneur creators (1K-10K subs)

### Round 2: Vocabulary Testing (If needed)
- **Goal:** Find exact words customers use for validated problem
- **Scope:** 5-8 variations of the same problem with different wording
- **Segment:** Same as Round 1

### Round 3: Segment Validation (If needed)
- **Goal:** Find which segment cares most about validated problem
- **Scope:** Same problem statements
- **Segment:** Test 2-3 different segments

### Round 4: Feature Prioritization (After MVP)
- **Goal:** Rank feature requests from beta users
- **Scope:** 10-12 potential features
- **Segment:** Active beta users

---

## Part 11: Common Pitfalls to Avoid

### Pitfall 1: Leading Questions
‚ùå **Bad:** "How frustrated are you with slow email design tools?"  
‚úÖ **Good:** "What is the most frustrating part of creating email campaigns?"

### Pitfall 2: Too Many Problem Statements
‚ùå **Bad:** 25 problems to rank (survey fatigue)  
‚úÖ **Good:** 12-15 problems maximum

### Pitfall 3: Vague Problem Statements
‚ùå **Bad:** "Email marketing is hard"  
‚úÖ **Good:** "Creating professional-looking email designs takes too long"

### Pitfall 4: Solution-Focused Statements
‚ùå **Bad:** "I need an AI tool to design my emails"  
‚úÖ **Good:** "Designing emails from scratch is overwhelming"

### Pitfall 5: Confirmation Bias
‚ùå **Bad:** Only counting votes that rank your problem high  
‚úÖ **Good:** Accepting results even if they contradict your assumptions

### Pitfall 6: Wrong Segment
‚ùå **Bad:** Surveying "anyone who sends emails"  
‚úÖ **Good:** Surveying "solopreneurs with 1K-10K subscriber lists"

### Pitfall 7: Ignoring Vocabulary Signals
‚ùå **Bad:** "Our problem ranked low, idea is invalidated"  
‚úÖ **Good:** "Did a different wording of our problem rank high?"

---

## Part 12: Success Metrics

### Research Quality Metrics

**Response Quality:**
- [ ] 80%+ of responses from target segment (filtered qualification)
- [ ] <5% of rankings are identical (indicates thoughtful ranking)
- [ ] 5+ new problems added by participants (indicates engagement)

**Statistical Confidence:**
- [ ] Minimum 30 qualified responses
- [ ] Top 3 problems have clear separation from #4-6
- [ ] Standard deviation <2.0 for top ranked problems

### Actionability Metrics

**Clear Signal:**
- [ ] Can state which problems are top 3 with confidence
- [ ] Can articulate why customers care about those problems
- [ ] Can explain in customer vocabulary (not your vocabulary)

**Next Steps:**
- [ ] Know exactly what to do next (build, pivot, or iterate)
- [ ] Have 10+ qualified beta tester prospects from respondents
- [ ] Have updated messaging ready to test

---

## Part 13: Templates & Resources

See separate documents:
- `cpsr-problem-statements.md` - All problem statements ready to copy/paste
- `cpsr-outreach-templates.md` - DM templates and community posts
- `cpsr-analysis-guide.md` - Spreadsheet templates and analysis formulas

---

## Timeline Summary

| Week | Activity | Time Investment |
|------|----------|-----------------|
| Week 0 | Survey setup | 2-3 hours |
| Week 1 | Distribution (outreach + posts) | 5-8 hours |
| Week 2 | Follow-ups + more distribution | 3-5 hours |
| Week 2-3 | Analysis + decision making | 2-4 hours |
| **Total** | | **12-20 hours** |

**Result:** In 2-3 weeks and <20 hours, you'll know if you're building the right thing.

---

## Key Takeaways

1. **CPSR reveals relative priority**, not just whether customers like your idea
2. **Vocabulary matters as much as the problem** - same problem, different words = different results
3. **Segment specificity prevents noisy data** - survey ONE specific segment at a time
4. **Accept invalidation gracefully** - better to learn now than after 6 months of building
5. **Iterate quickly** - run Round 2 with different vocabulary if needed

**The goal isn't to validate your idea. The goal is to learn the truth.**

---

## Next Steps

1. Read `cpsr-problem-statements.md` and customize for your positioning
2. Set up TypeForm survey (or Google Forms)
3. Read `cpsr-outreach-templates.md` and start finding respondents
4. Launch survey and aim for 30+ qualified responses
5. Use `cpsr-analysis-guide.md` to interpret results
6. Make go/no-go decision based on ranking

**Timeline to start:** You can launch this survey within 24 hours of reading this document.

Good luck! üöÄ

